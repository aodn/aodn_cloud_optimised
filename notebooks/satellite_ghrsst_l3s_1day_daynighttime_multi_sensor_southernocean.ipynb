{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c3eb1c37778d59",
   "metadata": {},
   "source": [
    "## Access Satellite Ghrsst L3S 1Day Daynighttime Multi Sensor Southern Ocean data in Parquet\n",
    "A jupyter notebook to show how to access and plot the AODN satellite_ghrsst_l3s_1day_daynighttime_multi_sensor_southernocean dataset available as a [Parquet](https://parquet.apache.org) dataset on S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db60797ca5fabcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"satellite_ghrsst_l3s_1day_daynighttime_multi_sensor_southernocean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166447a8-1632-439f-8fc8-17adf9e9318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import fsspec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f167c284-0324-49e7-8fcc-c57abde81ab1",
   "metadata": {},
   "source": [
    "## Install/Update packages and Load common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db6a4be5-7b34-44b1-b1cb-5bd053ba13d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: uv in /home/lbesnard/miniforge3/envs/AodnCloudOptimised/lib/python3.12/site-packages (0.4.18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPython 3.12.6 interpreter at: \u001b[36m/home/lbesnard/miniforge3/envs/AodnCloudOptimised/bin/python\u001b[39m\n",
      "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
      "Activate with: \u001b[32msource .venv/bin/activate\u001b[39m\n",
      "\u001b[2mAudited \u001b[1m129 packages\u001b[0m \u001b[2min 476ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# only run once, then restart session if needed\n",
    "!pip install uv\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def is_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "if is_colab():\n",
    "    os.system('uv pip install --system -r https://raw.githubusercontent.com/aodn/aodn_cloud_optimised/main/notebooks/requirements.txt')\n",
    "else:\n",
    "    os.system('uv venv')\n",
    "    os.system('uv pip install -r https://raw.githubusercontent.com/aodn/aodn_cloud_optimised/main/notebooks/requirements.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "285320a1-bfba-4344-a9fe-bc4b605b9fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "if not os.path.exists('parquet_queries.py'):\n",
    "  print('Downloading parquet_queries.py')\n",
    "  url = 'https://raw.githubusercontent.com/aodn/aodn_cloud_optimised/main/aodn_cloud_optimised/lib/ParquetDataQuery.py'\n",
    "  response = requests.get(url)\n",
    "  with open('parquet_queries.py', 'w') as f:\n",
    "      f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ecdd5e9-f208-4f77-8e5f-4cbdc5ebe787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parquet_queries import plot_gridded_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "521f88c5-01bc-4b77-88ad-2dba57457ab7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "conflicting sizes for dimension 'time': length 1038 on 'sea_ice_fraction_dtime_from_sst' and length 1068 on {'time': 'dt_analysis', 'lat': 'dt_analysis', 'lon': 'dt_analysis'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1147272/3697446193.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# remote zarr dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'\u001b[0m\u001b[0;34ms3://aodn-cloud-optimised/\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.zarr/\u001b[0m\u001b[0;34m'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_zarr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/AodnCloudOptimised/lib/python3.12/site-packages/xarray/backends/zarr.py\u001b[0m in \u001b[0;36mopen_zarr\u001b[0;34m(store, group, synchronizer, chunks, decode_cf, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, consolidated, overwrite_encoded_chunks, chunk_store, storage_options, decode_timedelta, use_cftime, zarr_version, chunked_array_type, from_array_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m     ds = open_dataset(\n\u001b[0m\u001b[1;32m   1098\u001b[0m         \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/AodnCloudOptimised/lib/python3.12/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0moverwrite_encoded_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overwrite_encoded_chunks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m     backend_ds = backend.open_dataset(\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0mdrop_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_variables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/AodnCloudOptimised/lib/python3.12/site-packages/xarray/backends/zarr.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, synchronizer, consolidated, chunk_store, storage_options, stacklevel, zarr_version, store, engine)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0mstore_entrypoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStoreBackendEntrypoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mclose_on_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             ds = store_entrypoint.open_dataset(\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0mmask_and_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_and_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/AodnCloudOptimised/lib/python3.12/site-packages/xarray/backends/store.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/AodnCloudOptimised/lib/python3.12/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_vars, coords, attrs)\u001b[0m\n\u001b[1;32m    709\u001b[0m             \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m         variables, coord_names, dims, indexes, _ = merge_data_and_coords(\n\u001b[0m\u001b[1;32m    712\u001b[0m             \u001b[0mdata_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/AodnCloudOptimised/lib/python3.12/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mmerge_data_and_coords\u001b[0;34m(data_vars, coords)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;31m# exclude coords from alignment (all variables in a Coordinates object should\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;31m# already be aligned together) and use coordinates' indexes to align data_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m     return merge_core(\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mdata_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mcompat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"broadcast_equals\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/AodnCloudOptimised/lib/python3.12/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mmerge_core\u001b[0;34m(objects, compat, join, combine_attrs, priority_arg, explicit_coords, indexes, fill_value, skip_align_args)\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m     \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0mcoord_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoncoord_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetermine_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoerced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/AodnCloudOptimised/lib/python3.12/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36mcalculate_dimensions\u001b[0;34m(variables)\u001b[0m\n\u001b[1;32m   3006\u001b[0m                 \u001b[0mlast_used\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3007\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3008\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   3009\u001b[0m                     \u001b[0;34mf\"\u001b[0m\u001b[0;34mconflicting sizes for dimension \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m!\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m: \u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3010\u001b[0m                     \u001b[0;34mf\"\u001b[0m\u001b[0;34mlength \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m on \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m!\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m and length \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m on \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mlast_used\u001b[0m\u001b[0;34m!\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: conflicting sizes for dimension 'time': length 1038 on 'sea_ice_fraction_dtime_from_sst' and length 1068 on {'time': 'dt_analysis', 'lat': 'dt_analysis', 'lon': 'dt_analysis'}"
     ]
    }
   ],
   "source": [
    "# remote zarr dataset\n",
    "url = f's3://aodn-cloud-optimised/{dataset_name}.zarr/'\n",
    "ds = xr.open_zarr(fsspec.get_mapper(url, anon=True), consolidated=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba52784-e07e-46b1-b7e5-d6c01a46d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gridded_variable(ds, start_date='2024-01-26', lon_slice=(4, 8), lat_slice=(-71, -69), var_name='sea_ice_fraction', n_days=9, coastline_resolution=\"10m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091429c0-84e4-4931-9bc6-78ec13ef887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gridded_variable(ds, start_date='2024-01-02', lon_slice=(3, 9), lat_slice=(-71, -65), var_name='sea_surface_temperature', coastline_resolution=\"10m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e11c75-d71f-4382-a174-1f551a43287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "\n",
    "def daily_avg_sea_ice_fraction(ds, lon_slice, lat_slice, start_date=None, end_date=None, var_name='sea_ice_fraction'):\n",
    "    \"\"\"\n",
    "    Computes and plots the daily average of sea_ice_fraction over a given region (lon_slice, lat_slice)\n",
    "    for a specified time range, bounded by dataset limits if necessary.\n",
    "\n",
    "    Parameters:\n",
    "    - ds: xarray.Dataset containing the sea ice data.\n",
    "    - lon_slice: tuple, longitude slice (start_lon, end_lon). (min val, max val)\n",
    "    - lat_slice: tuple, latitude slice (start_lat, end_lat). (min val, max val)\n",
    "    - start_date: str, start date in 'YYYY-MM-DD' format (optional).\n",
    "    - end_date: str, end date in 'YYYY-MM-DD' format (optional).\n",
    "    - var_name: str, variable name to calculate the average for (default is 'sea_ice_fraction').\n",
    "\n",
    "    Returns:\n",
    "    - xarray.Dataset containing the daily average of sea_ice_fraction for the specified region and time period.\n",
    "    \"\"\"\n",
    "\n",
    "    # Decide on the slice order\n",
    "    if ds.lat[0] < ds.lat[-1]:\n",
    "        lat_slice = lat_slice\n",
    "    elif ds.lat[0] > ds.lat[-1]:  \n",
    "        lat_slice = lat_slice[::-1]\n",
    "\n",
    "    # Ensure the dataset has a time dimension\n",
    "    assert 'time' in ds.dims, \"Dataset does not have a 'time' dimension\"\n",
    "\n",
    "    # Determine the dataset's time range\n",
    "    dataset_start = pd.to_datetime(ds.time.min().values)\n",
    "    dataset_end = pd.to_datetime(ds.time.max().values)\n",
    "\n",
    "    # Parse the start and end dates, default to dataset limits if necessary\n",
    "    start_date = pd.to_datetime(start_date) if start_date else dataset_start\n",
    "    end_date = pd.to_datetime(end_date) if end_date else dataset_end\n",
    "\n",
    "    # Bound the start and end dates within the dataset's time range\n",
    "    if start_date < dataset_start:\n",
    "        start_date = dataset_start\n",
    "    if end_date > dataset_end:\n",
    "        end_date = dataset_end\n",
    "\n",
    "    # Select the time range and area\n",
    "    selected_data = ds.sel(\n",
    "        lon=slice(lon_slice[0], lon_slice[1]),\n",
    "        lat=slice(lat_slice[0], lat_slice[1]),\n",
    "        time=slice(start_date, end_date)\n",
    "    )\n",
    "\n",
    "    # Compute the boolean masks for quality level and flags on the selected data\n",
    "    quality_mask = (selected_data['quality_level'] >= 4).compute()\n",
    "    flags_mask = (selected_data['l2p_flags'] != 2).compute()\n",
    "\n",
    "    # Apply masks to filter the dataset\n",
    "    filtered_ds = selected_data.where(quality_mask & flags_mask, drop=True)\n",
    "\n",
    "    # Calculate the daily average over the filtered area\n",
    "    daily_avg = filtered_ds[var_name].mean(dim=['lon', 'lat']).resample(time='1D').mean()\n",
    "\n",
    "    # Calculate percentage of non-NaN values\n",
    "    valid_data_count = filtered_ds[var_name].count(dim=['lon', 'lat']).resample(time='1D').sum()\n",
    "    total_data_count = selected_data[var_name].count(dim=['lon', 'lat']).resample(time='1D').sum()\n",
    "    percentage_valid = (valid_data_count / total_data_count) * 100\n",
    "\n",
    "    # Plot the time series of daily average sea_ice_fraction\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot daily average sea ice fraction\n",
    "    daily_avg.plot(ax=ax1, color='blue', marker='o', linestyle='-', label='Daily Avg Sea Ice Fraction')\n",
    "    ax1.set_ylabel(f\"{ds[var_name].attrs.get('units', 'unitless')} (%)\")\n",
    "    ax1.set_title(f\"Daily Average {ds[var_name].attrs.get('long_name', var_name)} ({start_date.date()} to {end_date.date()})\")\n",
    "    ax1.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f'{x * 100:.0f}%'))\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Create a second y-axis to plot percentage of valid data\n",
    "    ax2 = ax1.twinx()\n",
    "    percentage_valid.plot(ax=ax2, color='orange', marker='x', linestyle='-', label='Percentage of Measured Data Points in Grid')\n",
    "    ax2.set_ylabel(\"Percentage of Measured Data Points in Grid (%)\")\n",
    "    ax2.set_ylim(0, 100)  # Set limits for the percentage axis\n",
    "\n",
    "    # Combine legends\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Return the daily average as an xarray.Dataset\n",
    "    return daily_avg.to_dataset(name=f'daily_avg_{var_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d67510-1ab7-4f38-960a-60d5f516baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.sortby('time')\n",
    "result_ds = daily_avg_sea_ice_fraction(ds, lon_slice=(5, 7), lat_slice=(-71, -69), start_date='2024-01-26',  end_date='2024-02-20', var_name='sea_ice_fraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5e7272-5589-46bc-8828-160b34e2bc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
